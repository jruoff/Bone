import Functionalness.SourceAnalysis

/**
  * Entry point for aggregating the results generated by the compiler plugin.
  */
object Aggregator {
  import java.io.File
  import play.api.libs.json._
  import scalaz.effect.IO
  import IO.putStrLn

  def main(args: Array[String]): Unit = haskellMain(args.toList).unsafePerformIO()

  /** This entry point will read the analysis results of the individual source
    * files. It will aggregate and summarize the results which will be written
    * to disk.
    *
    * @param args Command line arguments. Not used.
    * @return The monadic process.
    */
  def haskellMain(args: List[String]): IO[Unit] = {
    import Functionalness._
    import scalaz.Scalaz._

    for {
      _ <- putStrLn("Aggregate results...")
      // TODO: Maybe a nicer solution would be: Files.newDirectoryStream(dir, "*.json")
      results <- recursiveListFiles(new File("bone"))
        .filter(_.getName.endsWith(".json"))
        .map(readAnalysis).sequence
      analyses = results filter (_.isSuccess) map (_.get)
      analysis = flatten((analyses map flatten).suml)
      _ <- putStrLn("Write aggregated results...")
      _ <- ExtraIO.write_all_utf8("bone_aggregated.json", Json.prettyPrint(Json.toJson(analysis)))
      _ <- putStrLn("Write normalized summary...")
      json_summary = Json.toJson(summary(analysis))
      _ <- ExtraIO.write_all_utf8("bone_summary.json", Json.prettyPrint(json_summary))
      _ <- ExtraIO.write_all_utf8("bone_summary.csv", jsonToCsv(json_summary) + "\n")
      _ <- putStrLn("Analysis completed.")
    } yield ()
  }

  def jsonToCsv(json: JsValue): String = json match {
    case obj: JsObject => obj.fields.map(pair => jsonToCsv(pair._2)).mkString(", ")
    case JsNumber(n) => n.toString
  }

  /** Read a SourceAnalysis object from a file.
    *
    * @param file The file to read from.
    * @return Monadic process returning the SourceAnalysis object as a JsResult.
    */
  def readAnalysis(file: File): IO[JsResult[SourceAnalysis]] =
    for {
      _    <- putStrLn("  " + file.toString)
      text <- ExtraIO.read_all_utf8(file.toString)
    } yield Json.fromJson[SourceAnalysis](Json.parse(text))

  /** Produce a stream of all files under a specific root.
    *
    * @param root The file representing the root of the directory tree to search.
    * @return A stream listing all files (excluding directories) under the given root.
    *         The root itself is only included if it is a file.
    */
  def recursiveListFiles(root: File): Stream[File] = {
    val children = root.listFiles
    if (children == null)
      Stream(root)
    else
      children.toStream.flatMap(recursiveListFiles)
  }
}
